{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the needed libs"
      ],
      "metadata": {
        "id": "1PKNxr0VapdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is written based on the github link :\n",
        "# https://github.com/ghadialhajj/FF_unsupervised"
      ],
      "metadata": {
        "id": "2vIXeauQhXQF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.signal import convolve2d\n",
        "from torch import tensor, Tensor\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "UoryvfyP2qnn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for preparing Mnist dataset - creating mask and negative data.\n",
        "## Negative batches will be chosen from negative images every time.\n",
        "all of them are based on the paper.\n",
        "We will plot the mask and the negative image at the end."
      ],
      "metadata": {
        "id": "EJzXSw08a0e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data():\n",
        "    # Define the transform function\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Load the train MNIST dataset\n",
        "    train_mnist_dataset = torchvision.datasets.MNIST(root=\"./\", train=True, transform=transform,\n",
        "                                                     download=True)\n",
        "    n_train_samples = len(train_mnist_dataset)\n",
        "    # Load the test MNIST dataset\n",
        "    test_mnist_dataset = torchvision.datasets.MNIST(root=\"./\", train=True, transform=transform,\n",
        "                                                    download=True)\n",
        "\n",
        "    if not os.path.exists(\"transformed_dataset.pt\"):\n",
        "        random_pairs = np.random.randint(n_train_samples, size=[n_train_samples, 2])\n",
        "        random_pairs = [(row[0], row[1]) for row in random_pairs]\n",
        "\n",
        "        # Transform the data\n",
        "        transformed_dataset = [\n",
        "            create_negative_image(train_mnist_dataset[pair[0]][0].squeeze(), train_mnist_dataset[pair[1]][0].squeeze())\n",
        "            for pair in tqdm(random_pairs)]\n",
        "\n",
        "        # Save the transformed images to a folder\n",
        "        torch.save(transformed_dataset, 'transformed_dataset.pt')\n",
        "\n",
        "\n",
        "def create_mask(shape, iterations: int = 10):\n",
        "    \"\"\"\n",
        "    Create a binary mask as described in (Hinton, 2022): start with a random binary image and then repeatedly blur\n",
        "    the image with a filter, horizontally and vertically.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    shape : tuple\n",
        "        The shape of the output mask (height, width).\n",
        "    iterations : int\n",
        "        The number of times to blur the image.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    numpy.ndarray\n",
        "        A binary mask with the specified shape, containing fairly large regions of ones and zeros.\n",
        "    \"\"\"\n",
        "\n",
        "    blur_filter_1 = np.array(((0, 0, 0), (0.25, 0.5, 0.25), (0, 0, 0)))\n",
        "    blur_filter_2 = blur_filter_1.T\n",
        "\n",
        "    # Create a random binary image\n",
        "    image = np.random.randint(0, 2, size=shape)\n",
        "\n",
        "    # Blur the image with the specified filter\n",
        "    for i in range(iterations):\n",
        "        image = np.abs(convolve2d(image, blur_filter_1, mode='same') / blur_filter_1.sum())\n",
        "        image = np.abs(convolve2d(image, blur_filter_2, mode='same') / blur_filter_2.sum())\n",
        "\n",
        "    # Binarize the blurred image, i.e. threshold it at 0.5\n",
        "    mask = np.round(image).astype(np.uint8)\n",
        "\n",
        "    return tensor(mask)\n",
        "\n",
        "\n",
        "def create_negative_image(image_1: Tensor, image_2: Tensor):\n",
        "    \"\"\"\n",
        "    Create a negative image by combining two images with a binary mask.\n",
        "\n",
        "    Args:\n",
        "        image_1 (Tensor): The first image to be combined.\n",
        "        image_2 (Tensor): The second image to be combined.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: The negative image created by combining the two input images.\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: If the shapes of `image_1` and `image_2` are not the same.\n",
        ",    [1, 1, 0, 0, 1]])\n",
        "    \"\"\"\n",
        "\n",
        "    assert image_1.shape == image_2.shape, \"Incompatible images and mask shapes.\"\n",
        "\n",
        "    mask = create_mask((image_1.shape[0], image_1.shape[1]))\n",
        "\n",
        "    image_1 = torch.mul(image_1, mask)\n",
        "    image_2 = torch.mul(image_2, 1 - mask)\n",
        "\n",
        "    return torch.add(image_1, image_2)\n",
        "\n",
        "\n",
        "def create_negative_batch(images: Tensor):\n",
        "    neg_imgs = []\n",
        "    batch_size = images.shape[0]\n",
        "    for _ in range(batch_size):\n",
        "        idx1, idx2 = np.random.randint(batch_size, size=2)\n",
        "        neg_imgs.append(create_negative_image(images[idx1].squeeze(), images[idx2].squeeze()))\n",
        "    return torch.unsqueeze(torch.stack(neg_imgs), dim=1)\n",
        "\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = torchvision.datasets.MNIST(root='data/', download=True)\n",
        "\n",
        "# Get the first instance of the digit 1\n",
        "image_1, _ = mnist[np.random.randint(len(mnist))]\n",
        "image_2, _ = mnist[np.random.randint(len(mnist))]\n",
        "\n",
        "image_1 = torch.as_tensor(np.asarray(image_1))\n",
        "image_2 = torch.as_tensor(np.asarray(image_2))\n",
        "\n",
        "mask = create_mask((28, 28))\n",
        "image = create_negative_image(image_1, image_2)\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Create the subplot\n",
        "fig, ax = plt.subplots(1, 5)\n",
        "images = [image_1, mask, image, 1 - mask, image_2]\n",
        "names = [\"image_1\", \"mask\", \"image\", \"1-mask\", \"image_2\"]\n",
        "# Add the images to the subplot\n",
        "for i, image in enumerate(images):\n",
        "    ax[i].imshow(image, cmap='gray')\n",
        "    ax[i].axis('off')\n",
        "    ax[i].set_title(names[i], y=-0.5)\n",
        "\n",
        "# Show the subplot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "JWx9u5g-APNr",
        "outputId": "279dd017-6102-4617-aefa-623576124f83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 110964436.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 105061312.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 99917524.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4651008.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "<ipython-input-3-dbc502cd6cbf>:105: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  image_1 = torch.as_tensor(np.asarray(image_1))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for the calculation of goodness in each layer.\n"
      ],
      "metadata": {
        "id": "CL1J5JKRbmoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_goodness(pos_acts, neg_acts, threshold=2):\n",
        "    \"\"\"\n",
        "    Compute the goodness score for a given set of positive and negative activations.\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "    pos_acts (torch.Tensor): Numpy array of positive activations.\n",
        "    neg_acts (torch.Tensor): Numpy array of negative activations.\n",
        "    threshold (int, optional): Threshold value used to compute the score. Default is 2.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    goodness (torch.Tensor): Goodness score computed as the sum of positive and negative goodness values. Note that this\n",
        "    score is actually the quantity that is optimized and not the goodness itself. The goodness itself is the same\n",
        "    quantity but without the threshold subtraction\n",
        "    \"\"\"\n",
        "\n",
        "    pos_goodness = -torch.sum(torch.pow(pos_acts, 2)) + threshold\n",
        "    neg_goodness = torch.sum(torch.pow(neg_acts, 2)) - threshold\n",
        "    return (torch.log(1 + torch.exp(torch.add(pos_goodness, neg_goodness)))).mean()\n",
        "\n",
        "\n",
        "def get_metrics(preds, labels):\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return dict(accuracy_score=acc)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n0UXUHKpAemg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition of the main layer class.\n",
        "## This class includes functions for train and forward process."
      ],
      "metadata": {
        "id": "gvCtlSyKb3gE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FF_Layer(nn.Linear):\n",
        "    def __init__(self, in_features: int, out_features: int, n_epochs: int, bias: bool, device):\n",
        "        super().__init__(in_features, out_features, bias=bias)\n",
        "        self.n_epochs = n_epochs\n",
        "        self.opt = torch.optim.Adam(self.parameters())\n",
        "        self.goodness = loss_goodness\n",
        "        self.to(device)\n",
        "        self.ln_layer = nn.LayerNorm(normalized_shape=[1, out_features]).to(device)\n",
        "\n",
        "    def ff_train(self, pos_acts, neg_acts):\n",
        "        \"\"\"\n",
        "        Train the layer using positive and negative activations.\n",
        "\n",
        "        Parameters:\n",
        "\n",
        "        pos_acts (numpy.ndarray): Numpy array of positive activations.\n",
        "        neg_acts (numpy.ndarray): Numpy array of negative activations.\n",
        "        \"\"\"\n",
        "\n",
        "        self.opt.zero_grad()\n",
        "        goodness = self.goodness(pos_acts, neg_acts)\n",
        "        goodness.backward()\n",
        "        self.opt.step()\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = super().forward(input)\n",
        "        input = self.ln_layer(input.detach())\n",
        "        return input\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "juaGJ5zlAptA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definition of FF class approximately as the same as the supervised version."
      ],
      "metadata": {
        "id": "4pgJEH1y-gkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Unsupervised_FF(nn.Module):\n",
        "    def __init__(self, n_layers: int = 4, n_neurons=2000, input_size: int = 28 * 28, n_epochs: int = 100,\n",
        "                 bias: bool = True, n_classes: int = 10, n_hid_to_log: int = 3, device=torch.device(\"cuda:0\")):\n",
        "        super().__init__()\n",
        "        self.n_hid_to_log = n_hid_to_log\n",
        "        self.n_epochs = n_epochs\n",
        "        self.device = device\n",
        "\n",
        "        ff_layers = [\n",
        "            FF_Layer(in_features=input_size if idx == 0 else n_neurons,\n",
        "                     out_features=n_neurons,\n",
        "                     n_epochs=n_epochs,\n",
        "                     bias=bias,\n",
        "                     device=device) for idx in range(n_layers)]\n",
        "\n",
        "        self.ff_layers = ff_layers\n",
        "        self.last_layer = nn.Linear(in_features=n_neurons * n_hid_to_log, out_features=n_classes, bias=bias)\n",
        "        self.to(device)\n",
        "        self.opt = torch.optim.Adam(self.last_layer.parameters())\n",
        "        self.loss = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "\n",
        "    def train_ff_layers(self, pos_dataloader, neg_dataloader):\n",
        "        outer_tqdm = tqdm(range(self.n_epochs), desc=\"Training FF Layers\", position=0)\n",
        "        for epoch in outer_tqdm:\n",
        "            inner_tqdm = tqdm(zip(pos_dataloader, neg_dataloader), desc=f\"Training FF Layers | Epoch {epoch}\",\n",
        "                              leave=False, position=1)\n",
        "            for pos_data, neg_imgs in inner_tqdm:\n",
        "                pos_imgs, _ = pos_data\n",
        "                pos_acts = torch.reshape(pos_imgs, (pos_imgs.shape[0], 1, -1)).to(self.device)\n",
        "                neg_acts = torch.reshape(neg_imgs, (neg_imgs.shape[0], 1, -1)).to(self.device)\n",
        "\n",
        "                for idx, layer in enumerate(self.ff_layers):\n",
        "                    pos_acts = layer(pos_acts)\n",
        "                    neg_acts = layer(neg_acts)\n",
        "                    layer.ff_train(pos_acts, neg_acts)\n",
        "\n",
        "    def train_last_layer(self, dataloader: DataLoader):\n",
        "        num_examples = len(dataloader)\n",
        "        outer_tqdm = tqdm(range(self.n_epochs), desc=\"Training Last Layer\", position=0)\n",
        "        loss_list = []\n",
        "        for epoch in outer_tqdm:\n",
        "            epoch_loss = 0\n",
        "            inner_tqdm = tqdm(dataloader, desc=f\"Training Last Layer | Epoch {epoch}\", leave=False, position=1)\n",
        "            for images, labels in inner_tqdm:\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                self.opt.zero_grad()\n",
        "                preds = self(images)\n",
        "                loss = self.loss(preds, labels)\n",
        "                epoch_loss += loss\n",
        "                loss.backward()\n",
        "                self.opt.step()\n",
        "            loss_list.append(epoch_loss / num_examples)\n",
        "            # Update progress bar with current loss\n",
        "        return [l.detach().cpu().numpy() for l in loss_list]\n",
        "\n",
        "    def forward(self, image: torch.Tensor):\n",
        "        image = image.to(self.device)\n",
        "        image = torch.reshape(image, (image.shape[0], 1, -1))\n",
        "        concat_output = []\n",
        "        for idx, layer in enumerate(self.ff_layers):\n",
        "            image = layer(image)\n",
        "            if idx > len(self.ff_layers) - self.n_hid_to_log - 1:\n",
        "                concat_output.append(image)\n",
        "        concat_output = torch.concat(concat_output, 2)\n",
        "        logits = self.last_layer(concat_output)\n",
        "        return logits.squeeze()\n",
        "\n",
        "    def evaluate(self, dataloader: DataLoader, dataset_type: str = \"train\"):\n",
        "        self.eval()\n",
        "        inner_tqdm = tqdm(dataloader, desc=f\"Evaluating model\", leave=False, position=1)\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "        for images, labels in inner_tqdm:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            preds = self(images)\n",
        "            preds = torch.argmax(preds, 1)\n",
        "            all_labels.append(labels.detach().cpu())\n",
        "            all_preds.append(preds.detach().cpu())\n",
        "        all_labels = torch.concat(all_labels, 0).numpy()\n",
        "        all_preds = torch.concat(all_preds, 0).numpy()\n",
        "        metrics_dict = get_metrics(all_preds, all_labels)\n",
        "        print(f\"{dataset_type} dataset scores: \", \"\\n\".join([f\"{key}: {value}\" for key, value in metrics_dict.items()]))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6Wuv4FK4AsyW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train function for calling the train of ff class."
      ],
      "metadata": {
        "id": "o9wVlv5r-zKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model: Unsupervised_FF, pos_dataloader: DataLoader, neg_dataloader: DataLoader):\n",
        "    model.train()\n",
        "    model.train_ff_layers(pos_dataloader, neg_dataloader)\n",
        "    return model.train_last_layer(pos_dataloader)\n",
        "\n",
        "\n",
        "def plot_loss(loss):\n",
        "    # plot the loss over epochs\n",
        "    fig = plt.figure()\n",
        "    plt.plot(list(range(len(loss))), loss)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Loss Plot\")\n",
        "    plt.savefig(\"Loss Plot.png\")\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jTzv9SvKAxK_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling the needed fucntions and preparing things to train the model and report the accuracy."
      ],
      "metadata": {
        "id": "dTFB5Q5k-69Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_data()\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "pos_dataset = torchvision.datasets.MNIST(root='./', download=False, transform=transform, train=True)\n",
        "# pos_dataset = Subset(pos_dataset, list(range(1000)))\n",
        "# Create the data loader\n",
        "pos_dataloader = DataLoader(pos_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "# Load the transformed images\n",
        "neg_dataset = torch.load('transformed_dataset.pt')\n",
        "# Create the data loader\n",
        "neg_dataloader = DataLoader(neg_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "# Load the test images\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, download=False, transform=transform)\n",
        "# Create the data loader\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "unsupervised_ff = Unsupervised_FF(device=device, n_epochs=2)\n",
        "\n",
        "loss = train(unsupervised_ff, pos_dataloader, neg_dataloader)\n",
        "\n",
        "plot_loss(loss)\n",
        "\n",
        "unsupervised_ff.evaluate(pos_dataloader, dataset_type=\"Train\")\n",
        "unsupervised_ff.evaluate(test_dataloader, dataset_type=\"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AM5WdwiEA1lo",
        "outputId": "c1962261-5f12-4de9-ccdd-5c3eb1f71f36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 316446657.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 104698093.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 91931188.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4542/4542 [00:00<00:00, 6899865.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [01:35<00:00, 630.22it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Training FF Layers:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Training FF Layers | Epoch 0: 0it [00:00, ?it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 1it [00:00,  1.71it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 6it [00:00, 11.02it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 11it [00:00, 19.24it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 16it [00:00, 25.93it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 21it [00:01, 31.40it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 27it [00:01, 37.11it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 32it [00:01, 39.35it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 37it [00:01, 40.99it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 42it [00:01, 40.84it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 47it [00:01, 42.25it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 52it [00:01, 42.06it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 57it [00:01, 42.57it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 62it [00:01, 42.92it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 69it [00:02, 48.53it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 76it [00:02, 53.72it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 83it [00:02, 56.78it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 90it [00:02, 58.62it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 96it [00:02, 58.51it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 103it [00:02, 61.14it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 111it [00:02, 64.85it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 118it [00:02, 64.81it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 126it [00:02, 67.25it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 133it [00:03, 66.98it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 140it [00:03, 67.72it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 147it [00:03, 67.12it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 155it [00:03, 68.71it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 162it [00:03, 67.14it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 169it [00:03, 66.78it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 176it [00:03, 65.99it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 184it [00:03, 67.02it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 191it [00:03, 67.05it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 199it [00:03, 68.39it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 207it [00:04, 70.69it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 215it [00:04, 68.91it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 222it [00:04, 68.88it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 229it [00:04, 68.87it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 236it [00:04, 67.22it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 244it [00:04, 69.16it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 252it [00:04, 70.14it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 260it [00:04, 70.64it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 268it [00:04, 71.01it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 276it [00:05, 70.02it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 284it [00:05, 70.43it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 292it [00:05, 70.96it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 300it [00:05, 71.63it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 308it [00:05, 68.17it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 316it [00:05, 69.77it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 324it [00:05, 70.54it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 332it [00:05, 72.95it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 340it [00:05, 71.70it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 348it [00:06, 70.47it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 356it [00:06, 72.19it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 364it [00:06, 72.37it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 372it [00:06, 71.54it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 380it [00:06, 71.46it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 388it [00:06, 70.61it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 396it [00:06, 69.92it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 404it [00:06, 71.51it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 413it [00:06, 73.56it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 421it [00:07, 72.28it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 429it [00:07, 72.53it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 437it [00:07, 71.90it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 445it [00:07, 70.20it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 453it [00:07, 68.48it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 460it [00:07, 67.63it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 468it [00:07, 68.61it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 476it [00:07, 69.81it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 483it [00:08, 69.72it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 491it [00:08, 70.13it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 499it [00:08, 69.32it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 507it [00:08, 70.14it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 515it [00:08, 69.60it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 523it [00:08, 70.88it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 531it [00:08, 67.68it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 539it [00:08, 69.22it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 547it [00:08, 69.14it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 554it [00:09, 68.95it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 562it [00:09, 69.95it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 570it [00:09, 69.78it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 578it [00:09, 70.52it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 586it [00:09, 70.83it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 594it [00:09, 71.27it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 602it [00:09, 70.93it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 610it [00:09, 70.44it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 618it [00:09, 71.13it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 626it [00:10, 71.17it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 634it [00:10, 72.08it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 642it [00:10, 72.11it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 650it [00:10, 70.67it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 658it [00:10, 70.53it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 666it [00:10, 72.17it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 674it [00:10, 70.73it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 682it [00:10, 70.72it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 690it [00:10, 68.03it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 697it [00:11, 67.95it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 704it [00:11, 67.94it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 711it [00:11, 67.09it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 718it [00:11, 67.06it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 725it [00:11, 67.68it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 733it [00:11, 70.30it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 741it [00:11, 67.46it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 749it [00:11, 68.80it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 756it [00:11, 67.99it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 763it [00:12, 60.76it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 770it [00:12, 56.03it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 776it [00:12, 53.90it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 782it [00:12, 52.69it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 788it [00:12, 49.92it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 794it [00:12, 43.12it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 799it [00:12, 42.60it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 804it [00:13, 41.12it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 809it [00:13, 40.37it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 815it [00:13, 43.01it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 820it [00:13, 43.91it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 825it [00:13, 45.13it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 830it [00:13, 46.13it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 835it [00:13, 46.40it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 840it [00:13, 45.45it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 846it [00:13, 48.79it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 851it [00:14, 48.66it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 857it [00:14, 49.12it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 862it [00:14, 46.87it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 867it [00:14, 47.15it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 873it [00:14, 47.99it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 878it [00:14, 48.02it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 883it [00:14, 48.50it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 888it [00:14, 47.44it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 893it [00:14, 47.73it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 898it [00:15, 45.13it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 903it [00:15, 43.77it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 908it [00:15, 44.53it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 913it [00:15, 45.10it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 919it [00:15, 45.88it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 924it [00:15, 46.67it/s]\u001b[A\n",
            "Training FF Layers | Epoch 0: 929it [00:15, 47.19it/s]\u001b[A\n",
            "Training FF Layers:  50%|█████     | 1/2 [00:16<00:16, 16.33s/it]\n",
            "Training FF Layers | Epoch 1: 0it [00:00, ?it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 1it [00:00,  5.77it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 6it [00:00, 23.97it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 12it [00:00, 34.66it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 18it [00:00, 41.30it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 23it [00:00, 40.70it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 28it [00:00, 42.19it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 33it [00:00, 44.04it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 38it [00:00, 42.40it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 43it [00:01, 43.17it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 48it [00:01, 44.72it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 56it [00:01, 53.59it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 64it [00:01, 59.64it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 72it [00:01, 64.25it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 79it [00:01, 64.20it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 87it [00:01, 66.17it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 94it [00:01, 66.58it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 101it [00:01, 66.63it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 108it [00:02, 67.41it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 115it [00:02, 67.87it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 123it [00:02, 68.28it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 130it [00:02, 68.10it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 137it [00:02, 68.61it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 144it [00:02, 68.29it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 151it [00:02, 64.62it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 158it [00:02, 63.22it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 165it [00:02, 64.21it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 172it [00:03, 65.67it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 179it [00:03, 65.83it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 186it [00:03, 66.44it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 193it [00:03, 66.61it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 200it [00:03, 65.77it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 208it [00:03, 68.17it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 215it [00:03, 67.44it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 222it [00:03, 67.11it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 229it [00:03, 66.90it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 236it [00:03, 67.29it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 243it [00:04, 67.47it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 250it [00:04, 67.35it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 258it [00:04, 68.69it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 265it [00:04, 68.74it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 272it [00:04, 68.71it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 280it [00:04, 70.86it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 288it [00:04, 67.74it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 296it [00:04, 70.41it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 304it [00:04, 69.04it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 311it [00:05, 68.02it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 318it [00:05, 68.33it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 325it [00:05, 66.02it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 333it [00:05, 67.13it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 340it [00:05, 67.38it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 348it [00:05, 68.42it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 355it [00:05, 66.86it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 362it [00:05, 65.95it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 369it [00:05, 65.52it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 376it [00:06, 66.19it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 384it [00:06, 67.95it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 391it [00:06, 67.24it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 399it [00:06, 69.09it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 407it [00:06, 70.34it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 415it [00:06, 68.24it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 423it [00:06, 69.33it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 430it [00:06, 66.56it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 437it [00:06, 67.40it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 444it [00:07, 67.48it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 451it [00:07, 68.16it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 458it [00:07, 63.38it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 465it [00:07, 63.06it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 472it [00:07, 63.25it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 479it [00:07, 63.13it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 486it [00:07, 63.38it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 493it [00:07, 64.36it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 500it [00:07, 65.29it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 507it [00:08, 65.84it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 514it [00:08, 65.06it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 521it [00:08, 63.72it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 528it [00:08, 65.36it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 535it [00:08, 63.44it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 543it [00:08, 65.36it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 550it [00:08, 65.08it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 557it [00:08, 64.34it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 564it [00:08, 63.06it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 571it [00:09, 63.23it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 578it [00:09, 64.10it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 585it [00:09, 65.08it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 593it [00:09, 66.50it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 601it [00:09, 68.13it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 609it [00:09, 70.24it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 617it [00:09, 69.15it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 625it [00:09, 70.75it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 633it [00:09, 69.97it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 641it [00:10, 69.86it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 649it [00:10, 72.54it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 657it [00:10, 69.57it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 665it [00:10, 68.80it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 673it [00:10, 70.37it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 681it [00:10, 71.27it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 689it [00:10, 70.35it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 697it [00:10, 71.18it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 705it [00:10, 67.81it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 712it [00:11, 66.90it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 719it [00:11, 67.64it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 726it [00:11, 59.22it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 733it [00:11, 55.26it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 739it [00:11, 54.93it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 745it [00:11, 53.67it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 751it [00:11, 51.60it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 757it [00:11, 49.15it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 762it [00:12, 47.89it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 767it [00:12, 47.04it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 772it [00:12, 46.52it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 777it [00:12, 45.98it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 782it [00:12, 45.38it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 787it [00:12, 45.20it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 792it [00:12, 46.03it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 798it [00:12, 47.61it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 803it [00:12, 47.41it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 808it [00:13, 47.86it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 813it [00:13, 48.13it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 819it [00:13, 48.85it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 824it [00:13, 47.64it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 829it [00:13, 47.60it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 834it [00:13, 47.34it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 839it [00:13, 47.58it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 844it [00:13, 47.37it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 849it [00:13, 44.92it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 854it [00:14, 46.01it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 859it [00:14, 45.68it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 864it [00:14, 46.14it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 869it [00:14, 46.55it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 875it [00:14, 48.11it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 880it [00:14, 47.98it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 885it [00:14, 47.52it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 891it [00:14, 48.07it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 897it [00:14, 48.01it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 902it [00:15, 45.93it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 908it [00:15, 47.87it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 913it [00:15, 47.40it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 918it [00:15, 47.99it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 924it [00:15, 49.02it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 929it [00:15, 48.35it/s]\u001b[A\n",
            "Training FF Layers | Epoch 1: 938it [00:15, 59.79it/s]\u001b[A\n",
            "Training FF Layers: 100%|██████████| 2/2 [00:32<00:00, 16.27s/it]\n",
            "Training Last Layer:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Training Last Layer | Epoch 0:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:   0%|          | 1/938 [00:00<09:11,  1.70it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:   1%|▏         | 13/938 [00:00<00:37, 24.80it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:   3%|▎         | 24/938 [00:00<00:21, 42.00it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:   4%|▎         | 34/938 [00:00<00:16, 55.39it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:   5%|▍         | 45/938 [00:01<00:13, 67.84it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:   6%|▌         | 57/938 [00:01<00:11, 79.82it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:   7%|▋         | 68/938 [00:01<00:10, 82.97it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:   8%|▊         | 79/938 [00:01<00:09, 88.04it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  10%|▉         | 91/938 [00:01<00:08, 94.35it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  11%|█         | 102/938 [00:01<00:08, 98.01it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  12%|█▏        | 113/938 [00:01<00:08, 99.87it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  13%|█▎        | 124/938 [00:01<00:08, 100.42it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  14%|█▍        | 135/938 [00:01<00:07, 102.15it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  16%|█▌        | 146/938 [00:01<00:07, 99.79it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  17%|█▋        | 158/938 [00:02<00:07, 104.36it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  18%|█▊        | 169/938 [00:02<00:07, 99.09it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  19%|█▉        | 181/938 [00:02<00:07, 102.34it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  20%|██        | 192/938 [00:02<00:07, 101.34it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  22%|██▏       | 203/938 [00:02<00:07, 99.67it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  23%|██▎       | 214/938 [00:02<00:07, 101.59it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  24%|██▍       | 225/938 [00:02<00:07, 100.74it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  25%|██▌       | 236/938 [00:02<00:07, 99.64it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  26%|██▌       | 246/938 [00:02<00:06, 98.97it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  27%|██▋       | 256/938 [00:03<00:06, 98.37it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  28%|██▊       | 267/938 [00:03<00:06, 101.31it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  30%|██▉       | 278/938 [00:03<00:06, 95.69it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  31%|███       | 289/938 [00:03<00:06, 99.32it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  32%|███▏      | 300/938 [00:03<00:06, 98.39it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  33%|███▎      | 312/938 [00:03<00:06, 101.80it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  34%|███▍      | 323/938 [00:03<00:06, 100.17it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  36%|███▌      | 335/938 [00:03<00:05, 101.28it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  37%|███▋      | 347/938 [00:03<00:05, 102.98it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  38%|███▊      | 358/938 [00:04<00:05, 104.89it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  39%|███▉      | 369/938 [00:04<00:05, 102.90it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  41%|████      | 380/938 [00:04<00:05, 98.48it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  42%|████▏     | 391/938 [00:04<00:05, 99.60it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  43%|████▎     | 402/938 [00:04<00:05, 102.41it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  44%|████▍     | 413/938 [00:04<00:05, 99.74it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  45%|████▌     | 424/938 [00:04<00:05, 100.30it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  46%|████▋     | 436/938 [00:04<00:04, 101.34it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  48%|████▊     | 447/938 [00:04<00:04, 99.04it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  49%|████▉     | 459/938 [00:05<00:04, 101.82it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  50%|█████     | 470/938 [00:05<00:04, 101.99it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  51%|█████▏    | 481/938 [00:05<00:04, 96.31it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  52%|█████▏    | 492/938 [00:05<00:04, 97.55it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  54%|█████▎    | 503/938 [00:05<00:04, 99.96it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  55%|█████▍    | 514/938 [00:05<00:04, 102.10it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  56%|█████▌    | 525/938 [00:05<00:04, 101.27it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  57%|█████▋    | 536/938 [00:05<00:03, 101.85it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  58%|█████▊    | 547/938 [00:05<00:03, 100.05it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  59%|█████▉    | 558/938 [00:06<00:03, 100.71it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  61%|██████    | 569/938 [00:06<00:03, 101.18it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  62%|██████▏   | 580/938 [00:06<00:03, 97.90it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  63%|██████▎   | 590/938 [00:06<00:03, 96.70it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  64%|██████▍   | 601/938 [00:06<00:03, 99.01it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  65%|██████▌   | 612/938 [00:06<00:03, 100.94it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  66%|██████▋   | 623/938 [00:06<00:03, 100.59it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  68%|██████▊   | 634/938 [00:06<00:03, 98.24it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  69%|██████▊   | 644/938 [00:06<00:03, 95.27it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  70%|██████▉   | 654/938 [00:07<00:02, 94.89it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  71%|███████   | 665/938 [00:07<00:02, 97.18it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  72%|███████▏  | 677/938 [00:07<00:02, 99.87it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  73%|███████▎  | 687/938 [00:07<00:02, 96.18it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  74%|███████▍  | 698/938 [00:07<00:02, 99.63it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  76%|███████▌  | 709/938 [00:07<00:02, 99.67it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  77%|███████▋  | 720/938 [00:07<00:02, 99.20it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  78%|███████▊  | 731/938 [00:07<00:02, 100.68it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  79%|███████▉  | 742/938 [00:07<00:01, 98.95it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  80%|████████  | 752/938 [00:08<00:01, 98.01it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  81%|████████▏ | 763/938 [00:08<00:01, 100.15it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  83%|████████▎ | 774/938 [00:08<00:01, 100.17it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  84%|████████▎ | 785/938 [00:08<00:01, 95.26it/s] \u001b[A\n",
            "Training Last Layer | Epoch 0:  85%|████████▍ | 797/938 [00:08<00:01, 99.99it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  86%|████████▌ | 808/938 [00:08<00:01, 100.24it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  87%|████████▋ | 820/938 [00:08<00:01, 101.69it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  89%|████████▊ | 831/938 [00:08<00:01, 103.13it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  90%|████████▉ | 842/938 [00:08<00:00, 101.08it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  91%|█████████ | 853/938 [00:09<00:00, 103.04it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  92%|█████████▏| 864/938 [00:09<00:00, 103.36it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  93%|█████████▎| 877/938 [00:09<00:00, 104.97it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  95%|█████████▍| 888/938 [00:09<00:00, 102.14it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  96%|█████████▌| 899/938 [00:09<00:00, 100.68it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  97%|█████████▋| 910/938 [00:09<00:00, 101.00it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  98%|█████████▊| 921/938 [00:09<00:00, 103.00it/s]\u001b[A\n",
            "Training Last Layer | Epoch 0:  99%|█████████▉| 932/938 [00:09<00:00, 101.58it/s]\u001b[A\n",
            "Training Last Layer:  50%|█████     | 1/2 [00:09<00:09,  9.93s/it]\n",
            "Training Last Layer | Epoch 1:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:   0%|          | 1/938 [00:00<02:54,  5.38it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:   1%|▏         | 12/938 [00:00<00:18, 49.53it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:   2%|▏         | 21/938 [00:00<00:15, 61.12it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:   3%|▎         | 30/938 [00:00<00:12, 70.53it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:   4%|▍         | 38/938 [00:00<00:13, 68.48it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:   5%|▍         | 46/938 [00:00<00:13, 63.76it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:   6%|▌         | 53/938 [00:00<00:14, 60.95it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:   7%|▋         | 62/938 [00:01<00:13, 65.36it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:   7%|▋         | 69/938 [00:01<00:13, 63.42it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:   8%|▊         | 76/938 [00:01<00:13, 63.96it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:   9%|▉         | 83/938 [00:01<00:14, 60.15it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  10%|▉         | 90/938 [00:01<00:13, 61.28it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  10%|█         | 97/938 [00:01<00:14, 58.32it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  11%|█         | 104/938 [00:01<00:13, 61.31it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  12%|█▏        | 111/938 [00:01<00:13, 63.27it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  13%|█▎        | 118/938 [00:01<00:13, 62.73it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  13%|█▎        | 125/938 [00:02<00:12, 64.30it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  14%|█▍        | 132/938 [00:02<00:12, 63.59it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  15%|█▍        | 140/938 [00:02<00:12, 65.33it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  16%|█▌        | 147/938 [00:02<00:12, 65.86it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  16%|█▋        | 154/938 [00:02<00:12, 63.97it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  17%|█▋        | 161/938 [00:02<00:11, 64.80it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  18%|█▊        | 168/938 [00:02<00:11, 66.15it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  19%|█▉        | 176/938 [00:02<00:11, 66.60it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  20%|█▉        | 183/938 [00:02<00:11, 66.32it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  20%|██        | 190/938 [00:03<00:11, 64.65it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  21%|██        | 197/938 [00:03<00:11, 64.58it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  22%|██▏       | 204/938 [00:03<00:11, 65.41it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  22%|██▏       | 211/938 [00:03<00:11, 64.77it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  23%|██▎       | 220/938 [00:03<00:10, 70.03it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  24%|██▍       | 228/938 [00:03<00:09, 71.71it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  25%|██▌       | 236/938 [00:03<00:10, 68.80it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  26%|██▌       | 243/938 [00:03<00:10, 68.11it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  27%|██▋       | 250/938 [00:03<00:11, 61.74it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  27%|██▋       | 257/938 [00:04<00:10, 63.27it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  28%|██▊       | 265/938 [00:04<00:10, 61.89it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  29%|██▉       | 273/938 [00:04<00:10, 65.55it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  30%|██▉       | 280/938 [00:04<00:10, 63.05it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  31%|███       | 287/938 [00:04<00:10, 64.51it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  31%|███▏      | 294/938 [00:04<00:10, 63.45it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  32%|███▏      | 301/938 [00:04<00:09, 65.02it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  33%|███▎      | 308/938 [00:04<00:10, 62.32it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  34%|███▎      | 316/938 [00:04<00:09, 62.76it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  35%|███▍      | 324/938 [00:05<00:09, 64.63it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  35%|███▌      | 331/938 [00:05<00:09, 63.25it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  36%|███▌      | 338/938 [00:05<00:09, 64.09it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  37%|███▋      | 345/938 [00:05<00:09, 64.33it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  38%|███▊      | 352/938 [00:05<00:08, 65.58it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  38%|███▊      | 359/938 [00:05<00:09, 63.61it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  39%|███▉      | 366/938 [00:05<00:08, 63.85it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  40%|███▉      | 374/938 [00:05<00:08, 68.01it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  41%|████      | 385/938 [00:05<00:06, 79.51it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  42%|████▏     | 394/938 [00:06<00:06, 80.92it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  43%|████▎     | 404/938 [00:06<00:06, 85.45it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  44%|████▍     | 415/938 [00:06<00:05, 90.78it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  45%|████▌     | 426/938 [00:06<00:05, 91.99it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  47%|████▋     | 437/938 [00:06<00:05, 93.55it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  48%|████▊     | 447/938 [00:06<00:05, 92.65it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  49%|████▉     | 458/938 [00:06<00:05, 95.94it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  50%|████▉     | 468/938 [00:06<00:04, 96.32it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  51%|█████     | 478/938 [00:06<00:04, 94.21it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  52%|█████▏    | 488/938 [00:07<00:04, 91.72it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  53%|█████▎    | 498/938 [00:07<00:04, 91.37it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  54%|█████▍    | 510/938 [00:07<00:04, 95.51it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  55%|█████▌    | 520/938 [00:07<00:04, 91.40it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  57%|█████▋    | 531/938 [00:07<00:04, 94.68it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  58%|█████▊    | 541/938 [00:07<00:04, 94.63it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  59%|█████▉    | 552/938 [00:07<00:03, 96.69it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  60%|█████▉    | 562/938 [00:07<00:03, 94.78it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  61%|██████    | 573/938 [00:07<00:03, 97.68it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  62%|██████▏   | 583/938 [00:08<00:03, 95.05it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  63%|██████▎   | 593/938 [00:08<00:03, 93.22it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  64%|██████▍   | 604/938 [00:08<00:03, 96.31it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  65%|██████▌   | 614/938 [00:08<00:03, 95.63it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  67%|██████▋   | 624/938 [00:08<00:03, 95.69it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  68%|██████▊   | 635/938 [00:08<00:03, 98.25it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  69%|██████▉   | 645/938 [00:08<00:02, 97.74it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  70%|██████▉   | 656/938 [00:08<00:02, 100.47it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  71%|███████   | 667/938 [00:08<00:02, 94.33it/s] \u001b[A\n",
            "Training Last Layer | Epoch 1:  72%|███████▏  | 678/938 [00:09<00:02, 98.42it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  73%|███████▎  | 688/938 [00:09<00:02, 94.98it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  75%|███████▍  | 699/938 [00:09<00:02, 95.85it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  76%|███████▌  | 709/938 [00:09<00:02, 96.31it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  77%|███████▋  | 720/938 [00:09<00:02, 100.12it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  78%|███████▊  | 731/938 [00:09<00:02, 97.09it/s] \u001b[A\n",
            "Training Last Layer | Epoch 1:  79%|███████▉  | 742/938 [00:09<00:02, 97.93it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  80%|████████  | 752/938 [00:09<00:01, 97.37it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  81%|████████  | 762/938 [00:09<00:01, 96.10it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  82%|████████▏ | 773/938 [00:10<00:01, 95.97it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  83%|████████▎ | 783/938 [00:10<00:01, 95.09it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  85%|████████▍ | 794/938 [00:10<00:01, 98.63it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  86%|████████▌ | 804/938 [00:10<00:01, 94.45it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  87%|████████▋ | 814/938 [00:10<00:01, 93.62it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  88%|████████▊ | 824/938 [00:10<00:01, 94.28it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  89%|████████▉ | 834/938 [00:10<00:01, 93.98it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  90%|████████▉ | 844/938 [00:10<00:00, 94.51it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  91%|█████████ | 854/938 [00:10<00:00, 96.07it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  92%|█████████▏| 864/938 [00:10<00:00, 93.59it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  93%|█████████▎| 874/938 [00:11<00:00, 94.11it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  94%|█████████▍| 886/938 [00:11<00:00, 101.39it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  96%|█████████▌| 897/938 [00:11<00:00, 97.95it/s] \u001b[A\n",
            "Training Last Layer | Epoch 1:  97%|█████████▋| 908/938 [00:11<00:00, 99.65it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  98%|█████████▊| 919/938 [00:11<00:00, 101.26it/s]\u001b[A\n",
            "Training Last Layer | Epoch 1:  99%|█████████▉| 930/938 [00:11<00:00, 101.35it/s]\u001b[A\n",
            "Training Last Layer: 100%|██████████| 2/2 [00:21<00:00, 10.84s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating model:   0%|          | 0/938 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating model:   0%|          | 1/938 [00:00<02:53,  5.40it/s]\u001b[A\n",
            "Evaluating model:   1%|          | 8/938 [00:00<00:27, 33.47it/s]\u001b[A\n",
            "Evaluating model:   2%|▏         | 19/938 [00:00<00:15, 61.26it/s]\u001b[A\n",
            "Evaluating model:   3%|▎         | 30/938 [00:00<00:11, 77.64it/s]\u001b[A\n",
            "Evaluating model:   4%|▍         | 41/938 [00:00<00:10, 87.31it/s]\u001b[A\n",
            "Evaluating model:   6%|▌         | 55/938 [00:00<00:08, 99.77it/s]\u001b[A\n",
            "Evaluating model:   7%|▋         | 66/938 [00:00<00:08, 101.82it/s]\u001b[A\n",
            "Evaluating model:   8%|▊         | 77/938 [00:00<00:08, 99.85it/s] \u001b[A\n",
            "Evaluating model:   9%|▉         | 89/938 [00:01<00:08, 105.41it/s]\u001b[A\n",
            "Evaluating model:  11%|█         | 100/938 [00:01<00:08, 103.66it/s]\u001b[A\n",
            "Evaluating model:  12%|█▏        | 112/938 [00:01<00:07, 107.76it/s]\u001b[A\n",
            "Evaluating model:  13%|█▎        | 123/938 [00:01<00:07, 107.52it/s]\u001b[A\n",
            "Evaluating model:  14%|█▍        | 134/938 [00:01<00:07, 104.78it/s]\u001b[A\n",
            "Evaluating model:  15%|█▌        | 145/938 [00:01<00:07, 105.34it/s]\u001b[A\n",
            "Evaluating model:  17%|█▋        | 158/938 [00:01<00:07, 108.78it/s]\u001b[A\n",
            "Evaluating model:  18%|█▊        | 170/938 [00:01<00:06, 111.89it/s]\u001b[A\n",
            "Evaluating model:  19%|█▉        | 182/938 [00:01<00:06, 110.25it/s]\u001b[A\n",
            "Evaluating model:  21%|██        | 194/938 [00:02<00:07, 106.05it/s]\u001b[A\n",
            "Evaluating model:  22%|██▏       | 205/938 [00:02<00:07, 102.91it/s]\u001b[A\n",
            "Evaluating model:  23%|██▎       | 216/938 [00:02<00:06, 104.38it/s]\u001b[A\n",
            "Evaluating model:  24%|██▍       | 227/938 [00:02<00:06, 103.24it/s]\u001b[A\n",
            "Evaluating model:  25%|██▌       | 238/938 [00:02<00:06, 103.96it/s]\u001b[A\n",
            "Evaluating model:  27%|██▋       | 252/938 [00:02<00:06, 113.70it/s]\u001b[A\n",
            "Evaluating model:  28%|██▊       | 264/938 [00:02<00:06, 108.97it/s]\u001b[A\n",
            "Evaluating model:  29%|██▉       | 275/938 [00:02<00:06, 105.75it/s]\u001b[A\n",
            "Evaluating model:  31%|███       | 287/938 [00:02<00:06, 101.97it/s]\u001b[A\n",
            "Evaluating model:  32%|███▏      | 299/938 [00:03<00:06, 103.11it/s]\u001b[A\n",
            "Evaluating model:  33%|███▎      | 310/938 [00:03<00:05, 104.73it/s]\u001b[A\n",
            "Evaluating model:  34%|███▍      | 322/938 [00:03<00:05, 108.72it/s]\u001b[A\n",
            "Evaluating model:  36%|███▌      | 333/938 [00:03<00:05, 108.62it/s]\u001b[A\n",
            "Evaluating model:  37%|███▋      | 345/938 [00:03<00:05, 110.68it/s]\u001b[A\n",
            "Evaluating model:  38%|███▊      | 357/938 [00:03<00:05, 110.00it/s]\u001b[A\n",
            "Evaluating model:  39%|███▉      | 369/938 [00:03<00:05, 107.21it/s]\u001b[A\n",
            "Evaluating model:  41%|████      | 380/938 [00:03<00:05, 94.75it/s] \u001b[A\n",
            "Evaluating model:  42%|████▏     | 390/938 [00:03<00:06, 88.50it/s]\u001b[A\n",
            "Evaluating model:  43%|████▎     | 400/938 [00:04<00:06, 81.84it/s]\u001b[A\n",
            "Evaluating model:  44%|████▎     | 409/938 [00:04<00:06, 77.80it/s]\u001b[A\n",
            "Evaluating model:  45%|████▍     | 419/938 [00:04<00:06, 81.22it/s]\u001b[A\n",
            "Evaluating model:  46%|████▌     | 428/938 [00:04<00:06, 77.89it/s]\u001b[A\n",
            "Evaluating model:  46%|████▋     | 436/938 [00:04<00:06, 76.70it/s]\u001b[A\n",
            "Evaluating model:  47%|████▋     | 444/938 [00:04<00:07, 68.89it/s]\u001b[A\n",
            "Evaluating model:  48%|████▊     | 452/938 [00:04<00:06, 70.26it/s]\u001b[A\n",
            "Evaluating model:  49%|████▉     | 460/938 [00:04<00:06, 69.74it/s]\u001b[A\n",
            "Evaluating model:  50%|████▉     | 468/938 [00:05<00:07, 66.91it/s]\u001b[A\n",
            "Evaluating model:  51%|█████     | 475/938 [00:05<00:06, 66.84it/s]\u001b[A\n",
            "Evaluating model:  51%|█████▏    | 483/938 [00:05<00:06, 67.36it/s]\u001b[A\n",
            "Evaluating model:  52%|█████▏    | 490/938 [00:05<00:06, 67.71it/s]\u001b[A\n",
            "Evaluating model:  53%|█████▎    | 497/938 [00:05<00:06, 67.98it/s]\u001b[A\n",
            "Evaluating model:  54%|█████▍    | 505/938 [00:05<00:06, 69.78it/s]\u001b[A\n",
            "Evaluating model:  55%|█████▍    | 513/938 [00:05<00:05, 72.25it/s]\u001b[A\n",
            "Evaluating model:  56%|█████▌    | 522/938 [00:05<00:05, 75.48it/s]\u001b[A\n",
            "Evaluating model:  57%|█████▋    | 530/938 [00:05<00:05, 73.47it/s]\u001b[A\n",
            "Evaluating model:  57%|█████▋    | 538/938 [00:06<00:05, 70.86it/s]\u001b[A\n",
            "Evaluating model:  58%|█████▊    | 546/938 [00:06<00:05, 69.11it/s]\u001b[A\n",
            "Evaluating model:  59%|█████▉    | 554/938 [00:06<00:05, 71.27it/s]\u001b[A\n",
            "Evaluating model:  60%|█████▉    | 562/938 [00:06<00:05, 71.16it/s]\u001b[A\n",
            "Evaluating model:  61%|██████    | 570/938 [00:06<00:05, 72.36it/s]\u001b[A\n",
            "Evaluating model:  62%|██████▏   | 579/938 [00:06<00:04, 75.15it/s]\u001b[A\n",
            "Evaluating model:  63%|██████▎   | 589/938 [00:06<00:04, 77.58it/s]\u001b[A\n",
            "Evaluating model:  64%|██████▎   | 597/938 [00:06<00:04, 77.03it/s]\u001b[A\n",
            "Evaluating model:  64%|██████▍   | 605/938 [00:06<00:04, 76.92it/s]\u001b[A\n",
            "Evaluating model:  65%|██████▌   | 613/938 [00:07<00:04, 75.32it/s]\u001b[A\n",
            "Evaluating model:  66%|██████▌   | 621/938 [00:07<00:04, 67.01it/s]\u001b[A\n",
            "Evaluating model:  67%|██████▋   | 629/938 [00:07<00:04, 69.77it/s]\u001b[A\n",
            "Evaluating model:  68%|██████▊   | 638/938 [00:07<00:04, 71.18it/s]\u001b[A\n",
            "Evaluating model:  69%|██████▉   | 646/938 [00:07<00:04, 69.86it/s]\u001b[A\n",
            "Evaluating model:  70%|██████▉   | 654/938 [00:07<00:03, 71.56it/s]\u001b[A\n",
            "Evaluating model:  71%|███████   | 663/938 [00:07<00:03, 73.93it/s]\u001b[A\n",
            "Evaluating model:  72%|███████▏  | 672/938 [00:07<00:03, 76.29it/s]\u001b[A\n",
            "Evaluating model:  73%|███████▎  | 682/938 [00:07<00:03, 78.57it/s]\u001b[A\n",
            "Evaluating model:  74%|███████▎  | 691/938 [00:08<00:03, 79.56it/s]\u001b[A\n",
            "Evaluating model:  75%|███████▍  | 699/938 [00:08<00:03, 76.97it/s]\u001b[A\n",
            "Evaluating model:  75%|███████▌  | 707/938 [00:08<00:03, 75.32it/s]\u001b[A\n",
            "Evaluating model:  76%|███████▌  | 715/938 [00:08<00:03, 72.98it/s]\u001b[A\n",
            "Evaluating model:  77%|███████▋  | 723/938 [00:08<00:02, 73.83it/s]\u001b[A\n",
            "Evaluating model:  78%|███████▊  | 732/938 [00:08<00:02, 76.45it/s]\u001b[A\n",
            "Evaluating model:  79%|███████▉  | 741/938 [00:08<00:02, 77.56it/s]\u001b[A\n",
            "Evaluating model:  80%|███████▉  | 749/938 [00:08<00:02, 77.13it/s]\u001b[A\n",
            "Evaluating model:  81%|████████  | 758/938 [00:08<00:02, 79.16it/s]\u001b[A\n",
            "Evaluating model:  82%|████████▏ | 770/938 [00:09<00:01, 90.29it/s]\u001b[A\n",
            "Evaluating model:  83%|████████▎ | 780/938 [00:09<00:01, 90.62it/s]\u001b[A\n",
            "Evaluating model:  84%|████████▍ | 792/938 [00:09<00:01, 97.99it/s]\u001b[A\n",
            "Evaluating model:  86%|████████▌ | 803/938 [00:09<00:01, 101.39it/s]\u001b[A\n",
            "Evaluating model:  87%|████████▋ | 816/938 [00:09<00:01, 108.48it/s]\u001b[A\n",
            "Evaluating model:  88%|████████▊ | 828/938 [00:09<00:01, 105.60it/s]\u001b[A\n",
            "Evaluating model:  90%|████████▉ | 840/938 [00:09<00:00, 109.13it/s]\u001b[A\n",
            "Evaluating model:  91%|█████████ | 851/938 [00:09<00:00, 104.63it/s]\u001b[A\n",
            "Evaluating model:  92%|█████████▏| 865/938 [00:09<00:00, 113.78it/s]\u001b[A\n",
            "Evaluating model:  93%|█████████▎| 877/938 [00:10<00:00, 114.51it/s]\u001b[A\n",
            "Evaluating model:  95%|█████████▍| 889/938 [00:10<00:00, 111.30it/s]\u001b[A\n",
            "Evaluating model:  96%|█████████▌| 901/938 [00:10<00:00, 104.63it/s]\u001b[A\n",
            "Evaluating model:  97%|█████████▋| 912/938 [00:10<00:00, 104.96it/s]\u001b[A\n",
            "Evaluating model:  99%|█████████▊| 924/938 [00:10<00:00, 105.63it/s]\u001b[A\n",
            "                                                                    \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset scores:  accuracy_score: 0.9072166666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating model:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Evaluating model:   1%|          | 1/157 [00:00<00:25,  6.08it/s]\u001b[A\n",
            "Evaluating model:   8%|▊         | 12/157 [00:00<00:02, 51.20it/s]\u001b[A\n",
            "Evaluating model:  13%|█▎        | 21/157 [00:00<00:02, 65.51it/s]\u001b[A\n",
            "Evaluating model:  22%|██▏       | 34/157 [00:00<00:01, 87.36it/s]\u001b[A\n",
            "Evaluating model:  28%|██▊       | 44/157 [00:00<00:01, 89.90it/s]\u001b[A\n",
            "Evaluating model:  37%|███▋      | 58/157 [00:00<00:00, 105.37it/s]\u001b[A\n",
            "Evaluating model:  45%|████▍     | 70/157 [00:00<00:00, 104.63it/s]\u001b[A\n",
            "Evaluating model:  52%|█████▏    | 82/157 [00:00<00:00, 107.17it/s]\u001b[A\n",
            "Evaluating model:  60%|█████▉    | 94/157 [00:01<00:00, 106.69it/s]\u001b[A\n",
            "Evaluating model:  68%|██████▊   | 106/157 [00:01<00:00, 107.39it/s]\u001b[A\n",
            "Evaluating model:  76%|███████▌  | 119/157 [00:01<00:00, 112.54it/s]\u001b[A\n",
            "Evaluating model:  83%|████████▎ | 131/157 [00:01<00:00, 110.99it/s]\u001b[A\n",
            "Evaluating model:  91%|█████████ | 143/157 [00:01<00:00, 109.74it/s]\u001b[A\n",
            "                                                                    \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset scores:  accuracy_score: 0.9082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train dataset scores:  accuracy_score: 0.9072166666666667\n",
        "\n",
        "## Test dataset scores:  accuracy_score: 0.9082"
      ],
      "metadata": {
        "id": "SO4vJI8W_IUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wR8o8_Zo_Fmx"
      }
    }
  ]
}