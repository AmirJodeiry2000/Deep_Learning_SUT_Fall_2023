{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" style=\"text-align: justify\"><font face=\"B Nazanin\" size=5>\n",
        "توضیحات :\n",
        "در این تمرین هدف پیاده سازی deformable conv و مقایسه آن با conv معمولی است.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "luZPdH3YAdXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torch.optim import SGD\n",
        "import time\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "q1CBipYoW6F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" style=\"text-align: justify\"><font face=\"B Nazanin\" size=4>\n",
        "توضیحات :\n",
        "در این قسمت با توجه به خواسته مسئله ( تغییر یافته MS coco به Mnist ) ابتدا دیتاست Mnist فراخوانی می شود.\n",
        "سپس دیتاست و لودر آن ساخته می شود.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "bKiiiiz7ArLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define transforms for MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Define data paths for MNIST (no annotation files needed for MNIST)\n",
        "train_data_path = 'data/MNIST/train'\n",
        "val_data_path = 'data/MNIST/test'\n",
        "\n",
        "# Create custom datasets for MNIST\n",
        "train_dataset = MNIST(root=train_data_path, train=True, download=True, transform=transform)\n",
        "val_dataset = MNIST(root=val_data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders for MNIST\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YDWrdyWn6IZ",
        "outputId": "2b44d885-6195-4b82-f48a-687d0bfb39c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/train/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 111018067.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/train/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/train/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/train/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 45522620.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/train/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/train/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/train/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 25049318.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/train/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/train/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/train/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7535810.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/train/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/train/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/test/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 107751806.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/test/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/test/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/test/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 109328243.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/test/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/test/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/test/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 34332605.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/test/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/test/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/test/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6808623.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/test/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/test/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" style=\"text-align: justify\"><font face=\"B Nazanin\" size=4>\n",
        "توضیحات :\n",
        "در این قسمت با توجه به هدف مسئله deformable conv پیاده سازی می شود.\n",
        "\n",
        "در اینجا یک لایهٔ کانولوشن (offset_conv) برای محاسبهٔ آفست‌ها ایجاد می‌شود. این لایه دو برابر اندازه کرنل kernel_size دارد تا بتواند دو مقدار برای هر نقطه در ورودی تولید کند.\n",
        "<br>\n",
        "\n",
        "<div dir=\"rtl\" style=\"text-align: justify\"><font face=\"B Nazanin\" size=4>\n",
        "لایهٔ دوم (modulator_conv) برای محاسبهٔ مدولاتورها ایجاد می‌شود. مدولاتورها از تابع فعال‌سازی sigmoid عبور داده می‌شوند.\n",
        "<br>\n",
        "<div dir=\"rtl\" style=\"text-align: justify\"><font face=\"B Nazanin\" size=4>\n",
        "لایهٔ سوم (regular_conv) به عنوان لایهٔ کانولوشن معمولی استفاده می‌شود.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "hkZi5NyPA8hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% based on https://github.com/developer0hye/PyTorch-Deformable-Convolution-v2/blob/main/dcn.py\n",
        "import torch\n",
        "import torchvision.ops\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class DeformableConv2d(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size=3,\n",
        "                 stride=1,\n",
        "                 padding=1,\n",
        "                 dilation=1,\n",
        "                 bias=False):\n",
        "        super(DeformableConv2d, self).__init__()\n",
        "\n",
        "        assert type(kernel_size) == tuple or type(kernel_size) == int\n",
        "\n",
        "        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n",
        "        self.stride = stride if type(stride) == tuple else (stride, stride)\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "\n",
        "        self.offset_conv = nn.Conv2d(in_channels,\n",
        "                                     2 * kernel_size[0] * kernel_size[1],\n",
        "                                     kernel_size=kernel_size,\n",
        "                                     stride=stride,\n",
        "                                     padding=self.padding,\n",
        "                                     dilation=self.dilation,\n",
        "                                     bias=True)\n",
        "\n",
        "        nn.init.constant_(self.offset_conv.weight, 0.)\n",
        "        nn.init.constant_(self.offset_conv.bias, 0.)\n",
        "\n",
        "        self.modulator_conv = nn.Conv2d(in_channels,\n",
        "                                        1 * kernel_size[0] * kernel_size[1],\n",
        "                                        kernel_size=kernel_size,\n",
        "                                        stride=stride,\n",
        "                                        padding=self.padding,\n",
        "                                        dilation=self.dilation,\n",
        "                                        bias=True)\n",
        "\n",
        "        nn.init.constant_(self.modulator_conv.weight, 0.)\n",
        "        nn.init.constant_(self.modulator_conv.bias, 0.)\n",
        "\n",
        "        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n",
        "                                      out_channels=out_channels,\n",
        "                                      kernel_size=kernel_size,\n",
        "                                      stride=stride,\n",
        "                                      padding=self.padding,\n",
        "                                      dilation=self.dilation,\n",
        "                                      bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # h, w = x.shape[2:]\n",
        "        # max_offset = max(h, w)/4.\n",
        "\n",
        "        offset = self.offset_conv(x)  # .clamp(-max_offset, max_offset)\n",
        "        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n",
        "        # op = (n - (k * d - 1) + 2p / s)\n",
        "        x = torchvision.ops.deform_conv2d(input=x,\n",
        "                                          offset=offset,\n",
        "                                          weight=self.regular_conv.weight,\n",
        "                                          bias=self.regular_conv.bias,\n",
        "                                          padding=self.padding,\n",
        "                                          mask=modulator,\n",
        "                                          stride=self.stride,\n",
        "                                          dilation=self.dilation)\n",
        "        return x"
      ],
      "metadata": {
        "id": "9krExJ8Pn7IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" style=\"text-align: justify\"><font face=\"B Nazanin\" size=4>\n",
        "در این قسمت یک مدل ساده براساس def conv و conv معمولی نوشته می شود.\n",
        "هدف مقایسه بین کارکرد دو نوع conv است.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "rAn0FV8tCz6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deformable Convolution Model\n",
        "class DeformableConvModel(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super(DeformableConvModel, self).__init__()\n",
        "\n",
        "        self.deformable_conv = DeformableConv2d(in_channels=1, out_channels=64, kernel_size=kernel_size, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=kernel_size, stride=2)\n",
        "\n",
        "        self.fc = nn.Linear(outputsize(outputsize(28 , kernel_size , 1 , 1), kernel_size , 2, 0)*outputsize(outputsize(28 , kernel_size , 1 , 1), kernel_size , 2, 0) * 64, 10)  # Output size is 10 for MNIST classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.deformable_conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Regular Convolution Model\n",
        "class RegularConvModel(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super(RegularConvModel, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=kernel_size, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=kernel_size, stride=2)\n",
        "\n",
        "        self.fc = nn.Linear(outputsize(outputsize(28 , kernel_size , 1 , 1), kernel_size , 2, 0)*outputsize(outputsize(28 , kernel_size , 1 , 1), kernel_size , 2, 0) * 64, 10)  # Output size is 10 for MNIST classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "def outputsize(I , k , s , p) :\n",
        "  o = int((np.floor((I-k+2*p)/s))+1)\n",
        "  return o"
      ],
      "metadata": {
        "id": "R52zmzeDoJFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" style=\"text-align: justify\"><font face=\"B Nazanin\" size=4>\n",
        "در این قسمت loss مورد نیاز تعریف می شود.\n",
        "<br>"
      ],
      "metadata": {
        "id": "9V_HHZCGDPR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ],
      "metadata": {
        "id": "bVSizi5tmip6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" style=\"text-align: justify\"><font face=\"B Nazanin\" size=4>\n",
        "در این قسمت دو تابع جهت train , eval مدل نوشته می شود.\n",
        "روند نوشتن توابع کاملا روش روتین ترینینگ است به طوری که مقدار مدل و نتیجه واقعی مقایسه شده و وزن ها آپدیت می شوند.\n",
        "<br>"
      ],
      "metadata": {
        "id": "-GPHWC2TDeb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Wrap your train_loader with tqdm for the progress bar\n",
        "    for inputs, targets in tqdm(train_loader, desc=\"Training\", leave=False):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "    duration = time.time() - start_time\n",
        "    accuracy = correct / total\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "\n",
        "    return accuracy, average_loss, duration\n",
        "\n",
        "# Validation loop\n",
        "def evaluate_model(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Wrap your val_loader with tqdm for the progress bar\n",
        "    for inputs, targets in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "    duration = time.time() - start_time\n",
        "    accuracy = correct / total\n",
        "    average_loss = total_loss / len(val_loader)\n",
        "\n",
        "    return accuracy, average_loss, duration\n"
      ],
      "metadata": {
        "id": "15JLWaiCm0WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" style=\"text-align: justify\"><font face=\"B Nazanin\" size=4>\n",
        "در نهایت 2 مدل به ازای kernel size های مختلف جهت مقایسه اثر grid sampling size مقایسه می شوند.\n",
        "به طوری که به ازای 5 ایپاک نتایج گزارش می شود.\n",
        "<br>"
      ],
      "metadata": {
        "id": "lnmtPVKtDyX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for kernel_size in range(2 , 5):\n",
        "  print('kernel_size = ' + str(kernel_size)+'\\n')\n",
        "  # Training and Evaluation\n",
        "  num_epochs = 5\n",
        "  # Instantiate models\n",
        "  deformable_model = DeformableConvModel(kernel_size = kernel_size).to(device)\n",
        "  regular_model = RegularConvModel(kernel_size = kernel_size).to(device)\n",
        "\n",
        "  # Loss function and optimizer\n",
        "  deformable_optimizer = SGD(deformable_model.parameters(), lr=0.001, momentum=0.9)\n",
        "  regular_optimizer = SGD(regular_model.parameters(), lr=0.001, momentum=0.9)\n",
        "  for epoch in range(num_epochs):\n",
        "      print('epoch = '+str(epoch+1)+ '\\n')\n",
        "      # Train Deformable Conv Model\n",
        "      deformable_train_accuracy, deformable_train_loss, deformable_train_duration = train_model(deformable_model, train_loader, criterion, deformable_optimizer, device)\n",
        "\n",
        "      # Evaluate Deformable Conv Model on Validation Set\n",
        "      deformable_val_accuracy, deformable_val_loss, deformable_val_duration = evaluate_model(deformable_model, val_loader, criterion, device)\n",
        "\n",
        "      # Train Regular Conv Model\n",
        "      regular_train_accuracy, regular_train_loss, regular_train_duration = train_model(regular_model, train_loader, criterion, regular_optimizer, device)\n",
        "\n",
        "      # Evaluate Regular Conv Model on Validation Set\n",
        "      regular_val_accuracy, regular_val_loss, regular_val_duration = evaluate_model(regular_model, val_loader, criterion, device)\n",
        "\n",
        "      # Print or log the metrics\n",
        "      print(f'Epoch [{epoch + 1}/{num_epochs}]')\n",
        "      print('Deformable Conv Model:')\n",
        "      print(f'Training Accuracy: {deformable_train_accuracy:.4f}, Training Loss: {deformable_train_loss:.4f}, Training Duration: {deformable_train_duration:.2f}s')\n",
        "      print(f'Validation Accuracy: {deformable_val_accuracy:.4f}, Validation Loss: {deformable_val_loss:.4f}, Validation Duration: {deformable_val_duration:.2f}s')\n",
        "\n",
        "      print('Regular Conv Model:')\n",
        "      print(f'Training Accuracy: {regular_train_accuracy:.4f}, Training Loss: {regular_train_loss:.4f}, Training Duration: {regular_train_duration:.2f}s')\n",
        "      print(f'Validation Accuracy: {regular_val_accuracy:.4f}, Validation Loss: {regular_val_loss:.4f}, Validation Duration: {regular_val_duration:.2f}s')\n",
        "      print('\\n')\n",
        "\n",
        "  # After training, you can use the trained models for further analysis or testing.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unFDiF50m16V",
        "outputId": "67cd3337-c1df-402b-e3ed-8246c544918e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kernel_size = 2\n",
            "\n",
            "epoch = 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.8855, Training Loss: 0.4198, Training Duration: 14.93s\n",
            "Validation Accuracy: 0.9172, Validation Loss: 0.2829, Validation Duration: 1.82s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.8781, Training Loss: 0.4317, Training Duration: 12.39s\n",
            "Validation Accuracy: 0.9141, Validation Loss: 0.2920, Validation Duration: 1.73s\n",
            "\n",
            "\n",
            "epoch = 2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9214, Training Loss: 0.2709, Training Duration: 15.05s\n",
            "Validation Accuracy: 0.9326, Validation Loss: 0.2398, Validation Duration: 2.65s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9162, Training Loss: 0.2871, Training Duration: 11.20s\n",
            "Validation Accuracy: 0.9291, Validation Loss: 0.2463, Validation Duration: 2.30s\n",
            "\n",
            "\n",
            "epoch = 3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9351, Training Loss: 0.2265, Training Duration: 13.66s\n",
            "Validation Accuracy: 0.9441, Validation Loss: 0.1952, Validation Duration: 1.81s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9254, Training Loss: 0.2564, Training Duration: 11.94s\n",
            "Validation Accuracy: 0.9338, Validation Loss: 0.2335, Validation Duration: 1.71s\n",
            "\n",
            "\n",
            "epoch = 4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9477, Training Loss: 0.1862, Training Duration: 13.67s\n",
            "Validation Accuracy: 0.9553, Validation Loss: 0.1600, Validation Duration: 1.84s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9329, Training Loss: 0.2331, Training Duration: 14.23s\n",
            "Validation Accuracy: 0.9370, Validation Loss: 0.2171, Validation Duration: 1.68s\n",
            "\n",
            "\n",
            "epoch = 5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9588, Training Loss: 0.1522, Training Duration: 13.89s\n",
            "Validation Accuracy: 0.9627, Validation Loss: 0.1335, Validation Duration: 1.82s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9400, Training Loss: 0.2124, Training Duration: 12.08s\n",
            "Validation Accuracy: 0.9403, Validation Loss: 0.2019, Validation Duration: 1.68s\n",
            "\n",
            "\n",
            "kernel_size = 3\n",
            "\n",
            "epoch = 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.8975, Training Loss: 0.3699, Training Duration: 13.81s\n",
            "Validation Accuracy: 0.9433, Validation Loss: 0.2033, Validation Duration: 1.84s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.8929, Training Loss: 0.3876, Training Duration: 12.19s\n",
            "Validation Accuracy: 0.9402, Validation Loss: 0.2130, Validation Duration: 1.70s\n",
            "\n",
            "\n",
            "epoch = 2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9487, Training Loss: 0.1820, Training Duration: 13.82s\n",
            "Validation Accuracy: 0.9634, Validation Loss: 0.1350, Validation Duration: 2.49s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9455, Training Loss: 0.1931, Training Duration: 11.53s\n",
            "Validation Accuracy: 0.9577, Validation Loss: 0.1500, Validation Duration: 2.59s\n",
            "\n",
            "\n",
            "epoch = 3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9648, Training Loss: 0.1269, Training Duration: 14.06s\n",
            "Validation Accuracy: 0.9710, Validation Loss: 0.1006, Validation Duration: 1.81s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9603, Training Loss: 0.1452, Training Duration: 12.30s\n",
            "Validation Accuracy: 0.9680, Validation Loss: 0.1191, Validation Duration: 1.72s\n",
            "\n",
            "\n",
            "epoch = 4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9722, Training Loss: 0.1000, Training Duration: 13.83s\n",
            "Validation Accuracy: 0.9760, Validation Loss: 0.0843, Validation Duration: 1.84s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9678, Training Loss: 0.1176, Training Duration: 12.17s\n",
            "Validation Accuracy: 0.9720, Validation Loss: 0.0999, Validation Duration: 1.71s\n",
            "\n",
            "\n",
            "epoch = 5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9765, Training Loss: 0.0850, Training Duration: 13.87s\n",
            "Validation Accuracy: 0.9788, Validation Loss: 0.0702, Validation Duration: 1.80s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9724, Training Loss: 0.1015, Training Duration: 12.26s\n",
            "Validation Accuracy: 0.9738, Validation Loss: 0.0909, Validation Duration: 1.73s\n",
            "\n",
            "\n",
            "kernel_size = 4\n",
            "\n",
            "epoch = 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9141, Training Loss: 0.3121, Training Duration: 14.07s\n",
            "Validation Accuracy: 0.9625, Validation Loss: 0.1406, Validation Duration: 2.67s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9118, Training Loss: 0.3233, Training Duration: 12.65s\n",
            "Validation Accuracy: 0.9586, Validation Loss: 0.1553, Validation Duration: 2.18s\n",
            "\n",
            "\n",
            "epoch = 2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9649, Training Loss: 0.1253, Training Duration: 14.26s\n",
            "Validation Accuracy: 0.9685, Validation Loss: 0.1008, Validation Duration: 2.20s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9622, Training Loss: 0.1373, Training Duration: 12.12s\n",
            "Validation Accuracy: 0.9723, Validation Loss: 0.1018, Validation Duration: 1.91s\n",
            "\n",
            "\n",
            "epoch = 3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9741, Training Loss: 0.0917, Training Duration: 13.94s\n",
            "Validation Accuracy: 0.9789, Validation Loss: 0.0710, Validation Duration: 1.83s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9717, Training Loss: 0.1013, Training Duration: 12.02s\n",
            "Validation Accuracy: 0.9769, Validation Loss: 0.0823, Validation Duration: 1.75s\n",
            "\n",
            "\n",
            "epoch = 4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9778, Training Loss: 0.0761, Training Duration: 13.95s\n",
            "Validation Accuracy: 0.9788, Validation Loss: 0.0749, Validation Duration: 1.78s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9768, Training Loss: 0.0837, Training Duration: 12.08s\n",
            "Validation Accuracy: 0.9784, Validation Loss: 0.0708, Validation Duration: 1.70s\n",
            "\n",
            "\n",
            "epoch = 5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                              "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5]\n",
            "Deformable Conv Model:\n",
            "Training Accuracy: 0.9809, Training Loss: 0.0665, Training Duration: 13.91s\n",
            "Validation Accuracy: 0.9822, Validation Loss: 0.0584, Validation Duration: 1.80s\n",
            "Regular Conv Model:\n",
            "Training Accuracy: 0.9795, Training Loss: 0.0728, Training Duration: 12.12s\n",
            "Validation Accuracy: 0.9810, Validation Loss: 0.0619, Validation Duration: 1.71s\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" style=\"text-align: justify\"><font face=\"B Nazanin\" size=4>\n",
        "همان طور که از نتایج مشاهده می شود. deformable conv در ایپاک کم تر به نتیجه بهتر از conv معمولی می رسد گرچه زمان training هر مرحله در def conv بیشتر  طول می کشد.\n",
        "<br>"
      ],
      "metadata": {
        "id": "Z6Tmfa0NEE6l"
      }
    }
  ]
}